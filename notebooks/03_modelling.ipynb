{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a6a106c2-f185-492f-87bb-79286c2eacc4",
   "metadata": {},
   "source": [
    "### __Predicting Airbnb Listing Prices in Sydney__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c9f6968-d9c2-422f-9935-eba856b3c028",
   "metadata": {},
   "source": [
    "--- \n",
    "## Task 3: Fit and Tune Prediction Models/ Produce predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14492c95",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5504fd88",
   "metadata": {},
   "source": [
    "#### Breakdown of the general procedure:\n",
    "\n",
    "✅ **1. Load Data**\n",
    "- Load cleaned dataset from `data/processed/processed_train.csv`\n",
    "- Split into `train` and `test` sets\n",
    "\n",
    "✅ **2. Train Multiple Models**\n",
    "- Linear Regression (baseline)\n",
    "- Decision Tree (simple tree-based model)\n",
    "- Random Forest (strong tree ensemble model)\n",
    "- Gradient Boosting, XGBoost, LightGBM (powerful boosting methods)\n",
    "- Voting Regressor (combines multiple models for better results)\n",
    "\n",
    "✅ **3. Cross-Validation**\n",
    "- Evaluate a model on multiple subsets of data\n",
    "\n",
    "✅ **4. Hyperparameter Tuning**\n",
    "- Uses GridSearchCV to find the best RandomForestRegressor parameters\n",
    "\n",
    "✅ **5. Compare Model Performance**\n",
    "- Saves R² scores for each model\n",
    "- Plots bar chart of model performance\n",
    "\n",
    "✅ **6. Save the Best Model**\n",
    "- Identifies the best-performing model\n",
    "- Saves it as `results/best_model.pkl`\n",
    "\n",
    "#### Models Selection Breakdown\n",
    "\n",
    "Since we're predicting **Airbnb listing prices** (a continuous numerical target), this is a regression problem. Based on the nature of given datasets and typical challenges in price prediction, I selected a mix of traditional ML models and ensemble learning methods to balance interpretability, predictive power, and generalization.\n",
    "\n",
    "To assist the hyperparameters tuning process, we utilize `K-fold Cross Validation` and `RandomizedSearchCV` method. Specifically, we select important parameters and set a suitable range for them so that the Random Search can identify the best performance with optimal parameters. For the _K-fold Cross Validation_ method, its purpose is to assess how well a ML model can generalize to unseen data by training and testing on different parts of the dataset multiple times and prevent overfitting.\n",
    "\n",
    "#### Models Selection Strategy\n",
    "1. Start with a simple model (`Linear Regression`) to establish a baseline\n",
    "2. Use `Decision Trees` to see how non-linear relationships improve results\n",
    "3. Apply `Ensemble Methods (Random Forest, Gradient Boosting)` to enhance predictive power\n",
    "4. Use `Advanced Boosting Models (XGBoost, LightGBM)` for optimized performance\n",
    "5. **Fine-tune hyperparameters** using `GridSearchCV` & `Bayesian Optimization`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b7aca9",
   "metadata": {},
   "source": [
    "### Import processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a18df367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Models \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor\n",
    "import xgboost as xgb\n",
    "# import lightgbm as lgb\n",
    "\n",
    "# Bayesian Optimization\n",
    "from skopt import BayesSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8d5bcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set display options for better readability\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "\n",
    "# Configure seaborn aesthetics\n",
    "sns.set(style=\"whitegrid\", palette=\"muted\", font_scale=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c357bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the processed train dataset \n",
    "df = pd.read_csv(r\"C:\\Users\\haiho\\GITHUB\\Sydney-Airbnb-prices-prediction\\data\\processed\\processed_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9183b94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['latitude', 'longitude', 'price'],axis=1) # Features\n",
    "y = df['price'] # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e934881f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>host_response_rate</th>\n",
       "      <th>host_acceptance_rate</th>\n",
       "      <th>host_is_superhost</th>\n",
       "      <th>host_listings_count</th>\n",
       "      <th>host_has_profile_pic</th>\n",
       "      <th>host_identity_verified</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>maximum_nights</th>\n",
       "      <th>minimum_minimum_nights</th>\n",
       "      <th>maximum_minimum_nights</th>\n",
       "      <th>minimum_maximum_nights</th>\n",
       "      <th>maximum_maximum_nights</th>\n",
       "      <th>minimum_nights_avg_ntm</th>\n",
       "      <th>maximum_nights_avg_ntm</th>\n",
       "      <th>has_availability</th>\n",
       "      <th>availability_30</th>\n",
       "      <th>availability_60</th>\n",
       "      <th>availability_90</th>\n",
       "      <th>availability_365</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>number_of_reviews_ltm</th>\n",
       "      <th>number_of_reviews_l30d</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>review_scores_accuracy</th>\n",
       "      <th>review_scores_cleanliness</th>\n",
       "      <th>review_scores_checkin</th>\n",
       "      <th>review_scores_communication</th>\n",
       "      <th>review_scores_location</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>calculated_host_listings_count_entire_homes</th>\n",
       "      <th>calculated_host_listings_count_private_rooms</th>\n",
       "      <th>calculated_host_listings_count_shared_rooms</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>email</th>\n",
       "      <th>phone</th>\n",
       "      <th>reviews</th>\n",
       "      <th>jumio</th>\n",
       "      <th>Long term stays allowed</th>\n",
       "      <th>Wifi</th>\n",
       "      <th>Essentials</th>\n",
       "      <th>Smoke alarm</th>\n",
       "      <th>mapped_property_type</th>\n",
       "      <th>mapped_bathrooms</th>\n",
       "      <th>mapped_room_type</th>\n",
       "      <th>response_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>174</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.67</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.67</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.67</td>\n",
       "      <td>4.33</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>61</td>\n",
       "      <td>336</td>\n",
       "      <td>383</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>4.42</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.40</td>\n",
       "      <td>4.77</td>\n",
       "      <td>4.67</td>\n",
       "      <td>4.70</td>\n",
       "      <td>4.47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>33</td>\n",
       "      <td>217</td>\n",
       "      <td>297</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>4.55</td>\n",
       "      <td>4.66</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.87</td>\n",
       "      <td>4.90</td>\n",
       "      <td>4.73</td>\n",
       "      <td>4.68</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>42</td>\n",
       "      <td>72</td>\n",
       "      <td>347</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.42</td>\n",
       "      <td>4.42</td>\n",
       "      <td>3.74</td>\n",
       "      <td>4.90</td>\n",
       "      <td>4.90</td>\n",
       "      <td>4.90</td>\n",
       "      <td>4.32</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>53</td>\n",
       "      <td>83</td>\n",
       "      <td>358</td>\n",
       "      <td>61</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>4.95</td>\n",
       "      <td>4.93</td>\n",
       "      <td>4.98</td>\n",
       "      <td>4.98</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.79</td>\n",
       "      <td>4.93</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  host_response_rate  host_acceptance_rate  host_is_superhost  \\\n",
       "0   0               100.0                  69.0                  1   \n",
       "1   1               100.0                 100.0                  0   \n",
       "2   2               100.0                  81.0                  1   \n",
       "3   3               100.0                 100.0                  1   \n",
       "4   4               100.0                  89.0                  1   \n",
       "\n",
       "   host_listings_count  host_has_profile_pic  host_identity_verified  \\\n",
       "0                  2.0                     1                       1   \n",
       "1                  3.0                     1                       1   \n",
       "2                  1.0                     1                       1   \n",
       "3                  1.0                     1                       1   \n",
       "4                  2.0                     1                       1   \n",
       "\n",
       "   accommodates  bedrooms  beds  minimum_nights  maximum_nights  \\\n",
       "0             6         3     3               2              22   \n",
       "1             2         1     1               2              90   \n",
       "2             4         1     1               2              90   \n",
       "3             4         2     2              90              90   \n",
       "4             4         2     3               1              30   \n",
       "\n",
       "   minimum_minimum_nights  maximum_minimum_nights  minimum_maximum_nights  \\\n",
       "0                       2                       2                      22   \n",
       "1                       2                       2                      90   \n",
       "2                       2                       2                      90   \n",
       "3                      90                      90                      90   \n",
       "4                       1                       1                      30   \n",
       "\n",
       "   maximum_maximum_nights  minimum_nights_avg_ntm  maximum_nights_avg_ntm  \\\n",
       "0                      22                       2                      22   \n",
       "1                      90                       2                      90   \n",
       "2                      90                       2                      90   \n",
       "3                      90                      90                      90   \n",
       "4                      30                       1                      30   \n",
       "\n",
       "   has_availability  availability_30  availability_60  availability_90  \\\n",
       "0                 1                0               14               14   \n",
       "1                 1                5               31               61   \n",
       "2                 1                1                9               33   \n",
       "3                 1               12               42               72   \n",
       "4                 1               26               53               83   \n",
       "\n",
       "   availability_365  number_of_reviews  number_of_reviews_ltm  \\\n",
       "0               174                  3                      1   \n",
       "1               336                383                     18   \n",
       "2               217                297                     15   \n",
       "3               347                 33                      1   \n",
       "4               358                 61                     15   \n",
       "\n",
       "   number_of_reviews_l30d  review_scores_rating  review_scores_accuracy  \\\n",
       "0                       0                  4.67                    4.33   \n",
       "1                       6                  4.42                    4.58   \n",
       "2                       4                  4.55                    4.66   \n",
       "3                       0                  4.42                    4.42   \n",
       "4                       0                  4.95                    4.93   \n",
       "\n",
       "   review_scores_cleanliness  review_scores_checkin  \\\n",
       "0                       4.33                   4.67   \n",
       "1                       4.40                   4.77   \n",
       "2                       4.23                   4.87   \n",
       "3                       3.74                   4.90   \n",
       "4                       4.98                   4.98   \n",
       "\n",
       "   review_scores_communication  review_scores_location  review_scores_value  \\\n",
       "0                         4.33                    4.67                 4.33   \n",
       "1                         4.67                    4.70                 4.47   \n",
       "2                         4.90                    4.73                 4.68   \n",
       "3                         4.90                    4.90                 4.32   \n",
       "4                         5.00                    4.79                 4.93   \n",
       "\n",
       "   instant_bookable  calculated_host_listings_count  \\\n",
       "0                 0                               2   \n",
       "1                 1                               1   \n",
       "2                 0                               1   \n",
       "3                 0                               1   \n",
       "4                 0                               1   \n",
       "\n",
       "   calculated_host_listings_count_entire_homes  \\\n",
       "0                                            2   \n",
       "1                                            0   \n",
       "2                                            1   \n",
       "3                                            1   \n",
       "4                                            0   \n",
       "\n",
       "   calculated_host_listings_count_private_rooms  \\\n",
       "0                                             0   \n",
       "1                                             1   \n",
       "2                                             0   \n",
       "3                                             0   \n",
       "4                                             1   \n",
       "\n",
       "   calculated_host_listings_count_shared_rooms  reviews_per_month  email  \\\n",
       "0                                            0               0.04      1   \n",
       "1                                            0               3.21      1   \n",
       "2                                            0               2.23      1   \n",
       "3                                            0               0.25      1   \n",
       "4                                            0               0.48      1   \n",
       "\n",
       "   phone  reviews  jumio  Long term stays allowed  Wifi  Essentials  \\\n",
       "0      1        1      1                        0     1           1   \n",
       "1      1        1      1                        1     1           1   \n",
       "2      1        1      1                        1     1           1   \n",
       "3      1        1      1                        1     1           1   \n",
       "4      1        1      1                        1     1           1   \n",
       "\n",
       "   Smoke alarm  mapped_property_type  mapped_bathrooms  mapped_room_type  \\\n",
       "0            1                     5               3.0                 4   \n",
       "1            1                     2               5.0                 3   \n",
       "2            1                     5               6.0                 4   \n",
       "3            1                     4               6.0                 4   \n",
       "4            1                     2               2.0                 3   \n",
       "\n",
       "   response_time  \n",
       "0              3  \n",
       "1              4  \n",
       "2              3  \n",
       "3              2  \n",
       "4              4  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d12f3ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train & test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "07feaa16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5600, 51)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c93613ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5600 entries, 1032 to 860\n",
      "Data columns (total 51 columns):\n",
      " #   Column                                        Non-Null Count  Dtype  \n",
      "---  ------                                        --------------  -----  \n",
      " 0   ID                                            5600 non-null   int64  \n",
      " 1   host_response_rate                            5600 non-null   float64\n",
      " 2   host_acceptance_rate                          5600 non-null   float64\n",
      " 3   host_is_superhost                             5600 non-null   int64  \n",
      " 4   host_listings_count                           5600 non-null   float64\n",
      " 5   host_has_profile_pic                          5600 non-null   int64  \n",
      " 6   host_identity_verified                        5600 non-null   int64  \n",
      " 7   accommodates                                  5600 non-null   int64  \n",
      " 8   bedrooms                                      5600 non-null   int64  \n",
      " 9   beds                                          5600 non-null   int64  \n",
      " 10  minimum_nights                                5600 non-null   int64  \n",
      " 11  maximum_nights                                5600 non-null   int64  \n",
      " 12  minimum_minimum_nights                        5600 non-null   int64  \n",
      " 13  maximum_minimum_nights                        5600 non-null   int64  \n",
      " 14  minimum_maximum_nights                        5600 non-null   int64  \n",
      " 15  maximum_maximum_nights                        5600 non-null   int64  \n",
      " 16  minimum_nights_avg_ntm                        5600 non-null   int64  \n",
      " 17  maximum_nights_avg_ntm                        5600 non-null   int64  \n",
      " 18  has_availability                              5600 non-null   int64  \n",
      " 19  availability_30                               5600 non-null   int64  \n",
      " 20  availability_60                               5600 non-null   int64  \n",
      " 21  availability_90                               5600 non-null   int64  \n",
      " 22  availability_365                              5600 non-null   int64  \n",
      " 23  number_of_reviews                             5600 non-null   int64  \n",
      " 24  number_of_reviews_ltm                         5600 non-null   int64  \n",
      " 25  number_of_reviews_l30d                        5600 non-null   int64  \n",
      " 26  review_scores_rating                          5600 non-null   float64\n",
      " 27  review_scores_accuracy                        5600 non-null   float64\n",
      " 28  review_scores_cleanliness                     5600 non-null   float64\n",
      " 29  review_scores_checkin                         5600 non-null   float64\n",
      " 30  review_scores_communication                   5600 non-null   float64\n",
      " 31  review_scores_location                        5600 non-null   float64\n",
      " 32  review_scores_value                           5600 non-null   float64\n",
      " 33  instant_bookable                              5600 non-null   int64  \n",
      " 34  calculated_host_listings_count                5600 non-null   int64  \n",
      " 35  calculated_host_listings_count_entire_homes   5600 non-null   int64  \n",
      " 36  calculated_host_listings_count_private_rooms  5600 non-null   int64  \n",
      " 37  calculated_host_listings_count_shared_rooms   5600 non-null   int64  \n",
      " 38  reviews_per_month                             5600 non-null   float64\n",
      " 39  email                                         5600 non-null   int64  \n",
      " 40  phone                                         5600 non-null   int64  \n",
      " 41  reviews                                       5600 non-null   int64  \n",
      " 42  jumio                                         5600 non-null   int64  \n",
      " 43  Long term stays allowed                       5600 non-null   int64  \n",
      " 44  Wifi                                          5600 non-null   int64  \n",
      " 45  Essentials                                    5600 non-null   int64  \n",
      " 46  Smoke alarm                                   5600 non-null   int64  \n",
      " 47  mapped_property_type                          5600 non-null   int64  \n",
      " 48  mapped_bathrooms                              5597 non-null   float64\n",
      " 49  mapped_room_type                              5600 non-null   int64  \n",
      " 50  response_time                                 5600 non-null   int64  \n",
      "dtypes: float64(12), int64(39)\n",
      "memory usage: 2.2 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1df89c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859a02d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save scaler\n",
    "joblib.dump(scaler, \"results/scaler.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db875ea6",
   "metadata": {},
   "source": [
    "### 1. Cross-Validation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f9b2a6",
   "metadata": {},
   "source": [
    "To ensure our model generalizes well to unseen data, we use **K-Fold Cross-Validation (CV)**. This method splits the dataset into multiple folds, trains the model on some folds, and tests it on the remaining ones. \n",
    "\n",
    "- We define a **5-fold cross-validation strategy** using `KFold`, ensuring reproducibility with `random_state=42`.\n",
    "- The `evaluate_model` function:\n",
    "  - Computes **cross-validation scores** using the R² metric.\n",
    "  - Prints the **mean R² score** and **standard deviation** to assess model stability.\n",
    "  - Returns the mean R² score for further evaluation.\n",
    "\n",
    "This approach helps us avoid overfitting and provides a robust estimate of model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e4b1aaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cross-validation strategy (5-fold)\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Helper function to evaluate models \n",
    "def evaluate_model(model, X, y):\n",
    "    scores = cross_val_score(model, X, y, cv=cv, scoring=\"r2\", n_jobs=-1)\n",
    "    print(f\"{model.__class__.__name__}: Mean R² = {scores.mean():.3f} | Std = {scores.std():.3f}\")\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caba93f6",
   "metadata": {},
   "source": [
    "### 2. Baseline Model (Linear Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9fdf7e",
   "metadata": {},
   "source": [
    "Multiple linear regression (MLR) uses several explanatory variables to predict the outcome of a dependent variable. The goal of multiple linear regression is to model the linear relationship between the explanatory (independent) variables and response (dependent) variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c36df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values in X_train: 3\n",
      "NaN values in y_train: 0\n",
      "Infinite values in X_train: 0\n",
      "Infinite values in y_train: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values\n",
    "print(\"NaN values in X_train:\", np.isnan(X_train).sum().sum())\n",
    "print(\"NaN values in y_train:\", np.isnan(y_train).sum())\n",
    "    \n",
    "# Check for infinite values\n",
    "print(\"Infinite values in X_train:\", np.isinf(X_train).sum().sum())\n",
    "print(\"Infinite values in y_train:\", np.isinf(y_train).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d3c5e1b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m lin_reg \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[1;32m----> 2\u001b[0m \u001b[43mlin_reg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m y_pred_lr \u001b[38;5;241m=\u001b[39m lin_reg\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLinear Regression - R²: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr2_score(y_test, y_pred_lr)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\haiho\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:662\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    658\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    660\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 662\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    664\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    667\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X, dtype\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\Users\\haiho\\anaconda3\\lib\\site-packages\\sklearn\\base.py:581\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    579\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 581\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    582\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\haiho\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:964\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    961\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    962\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my cannot be None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 964\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    979\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric)\n\u001b[0;32m    981\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mc:\\Users\\haiho\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:800\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    794\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    795\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    796\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    797\u001b[0m         )\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 800\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    803\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32mc:\\Users\\haiho\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:114\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    108\u001b[0m         allow_nan\n\u001b[0;32m    109\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39misinf(X)\u001b[38;5;241m.\u001b[39many()\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(X)\u001b[38;5;241m.\u001b[39mall()\n\u001b[0;32m    112\u001b[0m     ):\n\u001b[0;32m    113\u001b[0m         type_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfinity\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m allow_nan \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN, infinity\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    115\u001b[0m             msg_err\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    116\u001b[0m                 type_err, msg_dtype \u001b[38;5;28;01mif\u001b[39;00m msg_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m    117\u001b[0m             )\n\u001b[0;32m    118\u001b[0m         )\n\u001b[0;32m    119\u001b[0m \u001b[38;5;66;03m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan:\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = lin_reg.predict(X_test)\n",
    "print(f\"Linear Regression - R²: {r2_score(y_test, y_pred_lr):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f794c12d",
   "metadata": {},
   "source": [
    "### 3. Train Multiple Models with Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbb3bda",
   "metadata": {},
   "source": [
    "In this step, we train multiple regression models and evaluate their performance using **5-fold cross-validation**. \n",
    "\n",
    "- We define a dictionary of models, including:\n",
    "  - **Decision Tree**\n",
    "  - **Random Forest**\n",
    "  - **Gradient Boosting**\n",
    "  - **XGBoost**\n",
    "  - **LightGBM**\n",
    "\n",
    "- Each model is trained and evaluated using the previously defined `evaluate_model` function.\n",
    "- The results are stored in a **DataFrame** and sorted based on the **Mean R² score**, allowing us to compare model performance.\n",
    "\n",
    "This process helps us determine which model generalizes best to our dataset before further fine-tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12eadae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define multiple models with their parameters \n",
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeRegressor(random_state=42),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42),\n",
    "    \"XGBoost\": xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42),\n",
    "    \"LightGBM\": lgb.LGBMRegressor(n_estimators=100, learning_rate=0.1, random_state=42),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d316ec56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store cross-validation results\n",
    "cv_results = {name: evaluate_model(model, X_train, y_train) for name, model in models.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d403f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_results = pd.DataFrame(cv_results.items(), columns=[\"Model\", \"Mean R²\"]).sort_values(by=\"Mean R²\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4746599",
   "metadata": {},
   "source": [
    "### 4. Hyperparameter Tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be08a361",
   "metadata": {},
   "source": [
    "Selecting appropriate hyperparameter values for models like Random Forest, Gradient Boosting, XGBoost, and LightGBM is crucial for optimizing performance. Those ranges of values for each parameter of each model is carefully selected with a logic: \n",
    "- **Start with Defaults**: Begin with default settings to establish a baseline.\n",
    "- **Incremental Testing**: Adjust one parameter at a time to observe its impact.\n",
    "- **Cross-Validation**: Use techniques like GridSearchCV to systematically explore combinations.\n",
    "- **Computational Resources**: Balance the depth and number of trees with available resources to manage training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541ce950",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "    \"Random Forest\": {\n",
    "        \"n_estimators\": [100, 300, 500],\n",
    "        \"max_depth\": [10, 20, None],\n",
    "        \"min_samples_split\": [2, 5, 10],\n",
    "    },\n",
    "    \"Gradient Boosting\": {\n",
    "        \"n_estimators\": [100, 300, 500],\n",
    "        \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "        \"max_depth\": [3, 5, 7],\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"n_estimators\": [100, 300, 500],\n",
    "        \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "        \"max_depth\": [3, 6, 9],\n",
    "    },\n",
    "    \"LightGBM\": {\n",
    "        \"n_estimators\": [100, 300, 500],\n",
    "        \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "        \"num_leaves\": [20, 31, 40],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3a7c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n🔍 Tuning {name}...\")\n",
    "    grid_search = GridSearchCV(model, param_grids[name], cv=5, scoring=\"r2\", n_jobs=-1, verbose=1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_models[name] = grid_search.best_estimator_\n",
    "    print(f\"✅ Best {name} Parameters: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754eb1c7",
   "metadata": {},
   "source": [
    "### 5. Bayesian Optimization for Faster Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a6939d",
   "metadata": {},
   "source": [
    "In our Airbnb price prediction project, Bayesian Optimization serves as an advanced method for hyperparameter tuning. Unlike traditional approaches like grid or random search, Bayesian Optimization builds a probabilistic model of the objective function and uses this model to select the most promising hyperparameters to evaluate next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25098d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_params = {\n",
    "    \"Random Forest\": {\n",
    "        \"n_estimators\": (100, 500),\n",
    "        \"max_depth\": (5, 50),\n",
    "        \"min_samples_split\": (2, 10),\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"n_estimators\": (100, 500),\n",
    "        \"learning_rate\": (0.01, 0.3, \"log-uniform\"),\n",
    "        \"max_depth\": (3, 9),\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05817027",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_best_models = {}\n",
    "\n",
    "for name in [\"Random Forest\", \"XGBoost\"]:\n",
    "    print(f\"\\n🚀 Bayesian Optimization for {name}...\")\n",
    "    bayes_opt = BayesSearchCV(models[name], bayes_params[name], n_iter=20, cv=5, scoring=\"r2\", n_jobs=-1, verbose=1)\n",
    "    bayes_opt.fit(X_train, y_train)\n",
    "    bayes_best_models[name] = bayes_opt.best_estimator_\n",
    "    print(f\"✅ Best {name} Parameters (Bayesian): {bayes_opt.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a27d53",
   "metadata": {},
   "source": [
    "### 6. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2956f82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_models = {**best_models, **bayes_best_models}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b3404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {name: r2_score(y_test, model.predict(X_test)) for name, model in final_models.items()}\n",
    "df_results = pd.DataFrame(results.items(), columns=[\"Model\", \"R² Score\"]).sort_values(by=\"R² Score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e74f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(data=df_results, x=\"Model\", y=\"R² Score\", palette=\"coolwarm\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Final Model Performance Comparison\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64996603",
   "metadata": {},
   "source": [
    "### 7. Save the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fa427a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = df_results.iloc[0][\"Model\"]\n",
    "best_model = final_models[best_model_name]\n",
    "joblib.dump(best_model, f\"results/best_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e893c2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n✅ Best model saved: {best_model_name}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "64d55a98-90ac-45f5-b196-00088ec91282",
   "metadata": {},
   "source": [
    "### Model 1. Multiple Linear Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e9755cfb-5653-4720-a406-7721e8add383",
   "metadata": {},
   "source": [
    "`Overview:` \n",
    "\n",
    "Multiple linear regression (MLR) uses several explanatory variables to predict the outcome of a dependent variable. The goal of multiple linear regression is to model the linear relationship between the explanatory (independent) variables and response (dependent) variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0a0def-bb11-4030-b562-67952719c3c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE after applying Multiple Linear Regression: 57624.206\n",
      "R^2 after applying Multiple Linear Regression: 0.498\n"
     ]
    }
   ],
   "source": [
    "# Create MLR instance and fit the processed train data\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X, y)\n",
    "\n",
    "y_lr = lr.predict(X)\n",
    "\n",
    "# print(f'MSE after applying Multiple Linear Regression: {mean_squared_error(y, lr_y):.3f}')\n",
    "# print(f'R^2 after applying Multiple Linear Regression: {r2_score(y, lr_y):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38ba460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve MSE and R-Squared results after applying the model\n",
    "print(f'MSE after applying Multiple Linear Regression: {mean_squared_error(y, y_lr):.3f}')\n",
    "print(f'R^2 after applying Multiple Linear Regression: {r2_score(y, y_lr):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5fc49c-5ecf-4ab3-ba11-9ef2b0e4cf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cross-validation method to use\n",
    "cv_lr = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "\n",
    "# Apply k-fold CV to evaluate model performance\n",
    "scores_lr = cross_val_score(lr, X, y, scoring='neg_mean_squared_error', cv=cv_lr, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66f5ef4-c9f9-4706-a382-95b7892b3b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: -65113.582\n"
     ]
    }
   ],
   "source": [
    "# Print the c-v score for multiple linear regression model\n",
    "print(f'Cross validation score: {scores_lr.mean():.3f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ef734d53-994a-4ee1-84ff-287c852416f2",
   "metadata": {},
   "source": [
    "`Interpretation:`\n",
    "\n",
    "The Mean Squared Error seems too high and the model only captures nearly 50% of the variance in the target variable `price`. This therefore indicates that the train dataset does not follow a linear relationship significantly. However, other nonlinear regression models' outcomes are carefully assessed to reinforce this conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3535cc0-beb1-4d80-9c63-363da898c3a0",
   "metadata": {},
   "source": [
    "2 lists including Mean Squared Error results and cross validation scores are built to compare the performance of all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465509cc-a092-4263-a7f4-5b2a4c8605ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of MSE and cross validation scores of models\n",
    "model_mse = []\n",
    "model_mse.append(mean_squared_error(y, y_lr))\n",
    "\n",
    "model_scores = []\n",
    "model_scores.append(scores_lr.mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e2243a22-ac57-472d-915c-102a455954c1",
   "metadata": {},
   "source": [
    "### Model 2. Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc8bf15-8acc-48ef-af97-ccc63d40ab94",
   "metadata": {},
   "source": [
    "`Overview:` \n",
    "\n",
    "Random Forest is an ensemble technique capable of performing both regression and classification tasks with the use of multiple decision trees and a technique called Bootstrap Aggregation, commonly known as bagging. The basic idea behind this is to combine multiple decision trees in determining the final output rather than relying on individual decision trees."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fab7ff94-6bca-49fd-88f7-00c9f9de295b",
   "metadata": {},
   "source": [
    "`Default model:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acf05ef-757e-46e0-a46b-76b3f0a8186e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train after applying Random Forest Regression: 5577.452\n",
      "R^2 train after applying Random Forest Regression: 0.951\n"
     ]
    }
   ],
   "source": [
    "# Create RF instance\n",
    "forest = RandomForestRegressor()\n",
    "\n",
    "forest.fit(X, y)\n",
    "\n",
    "y_forest = forest.predict(X)\n",
    "\n",
    "# print(f'MSE train after applying Random Forest Regression: {mean_squared_error(y, y_forest):.3f}')\n",
    "# print(f'R^2 train after applying Random Forest Regression: {r2_score(y, y_forest):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949de876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve MSE and R-Squared results after applying the model\n",
    "print(f'MSE train after applying Random Forest Regression: {mean_squared_error(y, y_forest):.3f}')\n",
    "print(f'R^2 train after applying Random Forest Regression: {r2_score(y, y_forest):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d833451a-8639-4703-a344-c59f399c6f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: 0.624\n"
     ]
    }
   ],
   "source": [
    "# Use K-fold CV to evaluate model performance\n",
    "fr_scores = cross_val_score(forest, X, y, cv=cv, n_jobs=-1)\n",
    "print(f'Cross validation score: {fr_scores.mean():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1069ce-cd68-4fa8-b566-da8fcca2518f",
   "metadata": {},
   "source": [
    "`Interpretation:`\n",
    "\n",
    "The outputs of the **Random Forest Regression** model on train dataset is proved to be better than **Multiple Linear Regression** with a significantly lower MSE and a high R-squared value of 0.95 indicates that a larger proportion (95%) of the target features have been covered."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0374ecde-452d-4515-910c-c86ff066f294",
   "metadata": {},
   "source": [
    "`Tuning model:`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9b3d3b-68f3-48c6-ab13-90d210e9b56b",
   "metadata": {},
   "source": [
    "Hyperparameters tuning technique allows us to tune the hyperparameters to have best performance of the algorithm. In this case, there are a total of 5 important parameters that we will set value ranges for: \n",
    "- n_estimators: number of trees in the forest\n",
    "- max_depth: max number of levels in each decision tree \n",
    "- max_features: max number of features considered for splitting a node\n",
    "- criterion: method to check\n",
    "- bootstrap: method for sampling data points \n",
    "\n",
    "By using RandomizeSearchCV method, we can define a grid of hyperparameter ranges, and randomly from the grid, conducting K-Fold Cross Validation with each combination of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834bfb42-e40e-47fc-846f-f925417d0738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in Random Forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 50, stop = 300, num = 50)]\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [10,15]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = [int(x) for x in np.linspace(10, 3, num = 3)]\n",
    "\n",
    "# Criterion to split on\n",
    "criterion = ['mse']\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the grid\n",
    "grid = {'n_estimators': n_estimators,\n",
    "        'max_depth': max_depth,\n",
    "        'max_features': max_features,\n",
    "        'criterion': criterion,            \n",
    "        'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47587c5a-3e1b-4ce0-9f67-3841a90c2955",
   "metadata": {},
   "source": [
    "After fitting another Random Forest Regressor model and completing the random search, the optimal parameters for the model can be determined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "efc23457-6d59-44e9-b329-8211b6d79961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'criterion': ['mse'],\n",
       "                                        'max_depth': [10, 15],\n",
       "                                        'max_features': [10, 6, 3],\n",
       "                                        'n_estimators': [50, 55, 60, 65, 70, 75,\n",
       "                                                         80, 85, 90, 95, 101,\n",
       "                                                         106, 111, 116, 121,\n",
       "                                                         126, 131, 136, 141,\n",
       "                                                         146, 152, 157, 162,\n",
       "                                                         167, 172, 177, 182,\n",
       "                                                         187, 192, 197, ...]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 146,\n",
       " 'max_features': 10,\n",
       " 'max_depth': 15,\n",
       " 'criterion': 'mse',\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model to be tuned\n",
    "fr_tune = RandomForestRegressor()\n",
    "\n",
    "# Create the random search Random Forest\n",
    "fr_grid = RandomizedSearchCV(estimator = fr_tune, param_distributions = grid, cv = 3, verbose = 2, random_state = 42, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "fr_grid.fit(X, y)\n",
    "\n",
    "# View the best parameters from the random search\n",
    "fr_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b277286-7ec8-4bc4-936c-95be26ce7290",
   "metadata": {},
   "source": [
    "Now we re-fit the model with the best parameters achieved from the random search and generate the corresponding MSE and R-squared values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "aa0fc36e-375f-435d-aa80-237dd1faac38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, max_depth=15, max_features=10,\n",
       "                      n_estimators=146)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune_forest = RandomForestRegressor(n_estimators = 146, criterion = 'mse', max_features = 10, max_depth= 15, bootstrap=False) \n",
    "tune_forest.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f0a550e3-645a-43d0-96a1-033cf50b9132",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_forest_y = tune_forest.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "682c6e43-7498-443e-9743-40aec015c0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train after tuning hyperparameters: 950.539\n",
      "R^2 train after tunign hyperparameters: 0.992\n"
     ]
    }
   ],
   "source": [
    "print(f'MSE train after tuning hyperparameters: {mean_squared_error(y, tune_forest_y):.3f}')\n",
    "print(f'R^2 train after tunign hyperparameters: {r2_score(y, tune_forest_y):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a613c15b-0299-4c74-af46-87d0d4a1ee32",
   "metadata": {},
   "source": [
    "It is evident the model's performance has been significantly improved since the Mean Squared Error drops to below 100 and a nearly perfect R-squared value of 0.992 is recorded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "90ac1db5-0d9b-469f-bfee-ba7ae971305e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: 0.663\n"
     ]
    }
   ],
   "source": [
    "#use k-fold CV to evaluate model\n",
    "tune_fr_scores = cross_val_score(tune_forest, X, y, cv=cv, n_jobs=-1)\n",
    "print(f'Cross validation score: {tune_fr_scores.mean():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8331687-b8f0-4606-a4cb-f3ca2c282322",
   "metadata": {},
   "source": [
    "In comparison with the default model, the cross validation score of the tuned Random Forest is slight higher which also indicates improvements in the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6960ff93-64e5-4535-b258-27a55acd7b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append the outputs of the Random Forest models\n",
    "model_mse.append(mean_squared_error(y, forest_y))\n",
    "model_mse.append(mean_squared_error(y, tune_forest_y))\n",
    "model_scores.append(fr_scores.mean())\n",
    "model_scores.append(tune_fr_scores.mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c0f902d1-261b-498d-ab73-bf7f5ca43f8d",
   "metadata": {},
   "source": [
    "### Model 3. Bagging Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47883692-5627-4ef9-934a-18d81799d636",
   "metadata": {},
   "source": [
    "Overview: Bagging Regressor is an ensemble estimator which fits base estimator on each random subset of the training dataset and then aggregates their individual predictions to form a final prediction using voting or averaging method."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "88a01a4c-2e79-4ab9-ad80-ad781ee9341c",
   "metadata": {},
   "source": [
    "`Default model:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dc2f4bd1-7ce7-4b39-8d4c-2b62fa7968fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingRegressor()"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE after applying Bagging Regressor: 8031.500\n",
      "R^2 after applying Bagging Regressor: 0.930\n"
     ]
    }
   ],
   "source": [
    "#Create instance\n",
    "bag = BaggingRegressor()\n",
    "\n",
    "bag.fit(X, y)\n",
    "\n",
    "bag_y = bag.predict(X)\n",
    "\n",
    "print(f'MSE after applying Bagging Regressor: {mean_squared_error(y, bag_y):.3f}')\n",
    "print(f'R^2 after applying Bagging Regressor: {r2_score(y, bag_y):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d93158ee-59b2-44fc-bdd9-5414c2ef5abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: 0.603\n"
     ]
    }
   ],
   "source": [
    "#use k-fold CV to evaluate model\n",
    "bag_scores = cross_val_score(bag, X, y, cv=cv, n_jobs=-1)\n",
    "print(f'Cross validation score: {bag_scores.mean():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9237211b-8aa4-423d-8ef6-64d2168a56e0",
   "metadata": {},
   "source": [
    "*Interpretation:* \n",
    "\n",
    "The outputs of the default Bagging Regressor model seems to be not as good as those of Random Forest Regressor due to higher MSE and lower R-quared value (0.93). Therefore, we need to examine whether tuning hyperparameters can improve the model's performance or not."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e1f946c6-ed59-41ab-a29e-0920740660eb",
   "metadata": {},
   "source": [
    "`Tuning model:`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a2bdd8-77ad-4975-814e-28a57dfc548f",
   "metadata": {},
   "source": [
    "For the hyperparameters tuning process of the Bagging Regressor, we consider 4 main factors: \n",
    "- n_estimators: number of base estimators in the ensemble\n",
    "- max_features: number of features to train each base estimator \n",
    "- bootstrap: method for sampling data points\n",
    "- bootstrap_features: whether features are drawn with replacement or not.\n",
    "\n",
    "By using RandomizeSearchCV method, we can define a grid of hyperparameter ranges, and randomly from the grid, conducting K-Fold Cross Validation with each combination of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3af1dcb0-32f1-4cbc-b98a-376d1ca774ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_n_estimators = [int(x) for x in np.linspace(start = 50, stop = 300, num = 50)]\n",
    "\n",
    "bag_max_features = [int(x) for x in np.linspace(10, 3, num = 3)]\n",
    "\n",
    "bag_bootstrap = [True, False]\n",
    "bag_bootstrap_features = [True, False]\n",
    "\n",
    "# Create the grid\n",
    "bag_grid = {'n_estimators': bag_n_estimators,\n",
    "        'max_features': bag_max_features,\n",
    "        'bootstrap': bag_bootstrap,\n",
    "        'bootstrap_features': bag_bootstrap_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b0294603-c1df-4d3e-89f7-667c9f1c4ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=BaggingRegressor(),\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'bootstrap_features': [True, False],\n",
       "                                        'max_features': [10, 6, 3],\n",
       "                                        'n_estimators': [50, 55, 60, 65, 70, 75,\n",
       "                                                         80, 85, 90, 95, 101,\n",
       "                                                         106, 111, 116, 121,\n",
       "                                                         126, 131, 136, 141,\n",
       "                                                         146, 152, 157, 162,\n",
       "                                                         167, 172, 177, 182,\n",
       "                                                         187, 192, 197, ...]})"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_tune = BaggingRegressor()\n",
    "tune_bag = RandomizedSearchCV(bag_tune, param_distributions=bag_grid)\n",
    "tune_bag.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1ad4ece8-6b4f-4e9a-b07e-bf4e3b6bcd4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 157,\n",
       " 'max_features': 10,\n",
       " 'bootstrap_features': False,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View the best parameters from the random search\n",
    "tune_bag.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "49ab7085-68b1-4358-9bce-f2ba955c2878",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_bag_y = tune_bag.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c8e72cd9-5e5a-4738-9d42-f0c92906706d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train after tuning hyperparameters: 8419.433\n",
      "R^2 train after tuning hyperparameters: 0.927\n"
     ]
    }
   ],
   "source": [
    "print(f'MSE train after tuning hyperparameters: {mean_squared_error(y, tune_bag_y):.3f}')\n",
    "print(f'R^2 train after tuning hyperparameters: {r2_score(y, tune_bag_y):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ce66345b-2c05-4a7a-8ac1-f125f8f25fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: 0.590\n"
     ]
    }
   ],
   "source": [
    "#Use k-fold CV to evaluate model\n",
    "tune_bag_scores = cross_val_score(tune_bag, X, y, cv=cv, n_jobs=-1)\n",
    "print(f'Cross validation score: {tune_bag_scores.mean():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d635ac88-dd87-4d81-babe-f7a75e12720d",
   "metadata": {},
   "source": [
    "*Interpretation:* \n",
    "\n",
    "The Bagging Regressor model after tuning hyperparameters clearly has a similar as the default model as there is not significant difference between their MSE or R-squared. Overall, not only for this model but also the Random Forest Regressor, changing parameters allows us to significantly improve the models' performances. Now we can compare all models to determine which one is the most desirable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0d506890-8340-4889-9409-33f5fd313ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append the outputs of the Bagging models\n",
    "model_mse.append(mean_squared_error(y, bag_y))\n",
    "model_mse.append(mean_squared_error(y, tune_bag_y))\n",
    "model_scores.append(bag_scores.mean())\n",
    "model_scores.append(tune_bag_scores.mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "75d0e8d7-091a-428a-990b-853857485a49",
   "metadata": {},
   "source": [
    "### Models Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3d3da6-5c11-4cd3-b633-48cff48eb2f6",
   "metadata": {},
   "source": [
    "We set up 2 new dataframes for all models' MSE and cross-validation scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9054dd3e-5d64-4c36-b08c-49a72e668318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Type</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLR</td>\n",
       "      <td>57624.205877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>5577.451734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adjusted RF</td>\n",
       "      <td>950.538941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BR</td>\n",
       "      <td>8031.500430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adjusted BR</td>\n",
       "      <td>8419.432886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model Type           MSE\n",
       "0          MLR  57624.205877\n",
       "1           RF   5577.451734\n",
       "2  Adjusted RF    950.538941\n",
       "3           BR   8031.500430\n",
       "4  Adjusted BR   8419.432886"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_mse = [\"MLR\", \"RF\", \"Adjusted RF\", \"BR\", \"Adjusted BR\" ]\n",
    "df_mse = pd.DataFrame(models_mse, columns=[\"Model Type\"])\n",
    "df_mse[\"MSE\"] = model_mse\n",
    "df_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7901e53e-a060-49e7-af9c-da2e35787940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Type</th>\n",
       "      <th>Cross-validation score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLR</td>\n",
       "      <td>-65113.582334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.624418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adjusted RF</td>\n",
       "      <td>0.663365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BR</td>\n",
       "      <td>0.602642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adjusted BR</td>\n",
       "      <td>0.590407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model Type  Cross-validation score\n",
       "0          MLR           -65113.582334\n",
       "1           RF                0.624418\n",
       "2  Adjusted RF                0.663365\n",
       "3           BR                0.602642\n",
       "4  Adjusted BR                0.590407"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_crossvalscores = [\"MLR\", \"RF\", \"Adjusted RF\", \"BR\", \"Adjusted BR\" ]\n",
    "df_scores = pd.DataFrame(models_crossvalscores, columns=[\"Model Type\"])\n",
    "df_scores[\"Cross-validation score\"] = model_scores\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf545dd-d1f2-40c1-a3cf-706515e9f35a",
   "metadata": {},
   "source": [
    "Now we can visualize both datasets to have a better consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "bf11a5b3-6b57-4368-841d-d1f44ab9f3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x288 with 0 Axes>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12245b89f40>]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Models')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'MSE')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting the mse outputs\n",
    "plt.figure(figsize = (10,4))\n",
    "plt.plot(df_mse[\"Model Type\"], df_mse[\"MSE\"])\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "18504f67-0701-4182-a4e9-ddbfd97cf1d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x288 with 0 Axes>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12245ae91f0>]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Models')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'cross_val_score')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAn8AAAEGCAYAAAAUi/NvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAsGklEQVR4nO3deZgU5b3+//fNvgjIprIvIioKooyIJjEuRHBXNAkmUWI8X6LHnJzkd5IILsE1amKOiUk0GndPEk1EFHdx1xO3QZEBFBkFEUEBh01AYGY+vz+65tjiANMwPTUzfb+uqy+6n6qn+y56evozT9VTpYjAzMzMzApDk7QDmJmZmVndcfFnZmZmVkBc/JmZmZkVEBd/ZmZmZgXExZ+ZmZlZAWmWdoD6qEuXLtG3b9+0Y5iZmZlt0/Tp05dHRNearu/irxp9+/aluLg47RhmZmZm2yTp/VzW925fMzMzswLi4s/MzMysgLj4MzMzMysgLv7MzMzMCoiLPzMzM7MCUjDFn6TRkuZKKpU0Ie08ZmZmZmkoiOJPUlPgT8DRwCDgNEmD0k1lZmZmVvcK5Tx/w4HSiHgPQNLdwInAnFRTWcHZUF7B315ZyIq1G9OOYmZmdaBnpzZ8q6hX2jG+oFCKvx7AB1mPFwEHZa8gaTwwHqB37951l8wKynVPzeNPz7yLlHYSMzOrCwf37+ziLyXVfdXGFx5E3ATcBFBUVBTVrG+2Q+YsXs2Nz73HqcN6cs0390s7jpmZFaiCOOaPzEhfdtndE1icUhYrQOUVlUy4byY7t2nOBcfsnXYcMzMrYIVS/L0G7CGpn6QWwFhgasqZrIDc/q8FzFy0iknH70PHti3SjmNmZgWsIHb7RkS5pB8BjwNNgVsjYnbKsaxALPxkHdc8MZeRe+/CcUO6pR3HzMwKXEEUfwAR8QjwSNo5rLBEBBfcX0KzJk247KR9kWd6mJlZygplt69ZKu57/UNemLec80bvSbcOrdOOY2Zm5uLPLF+Wf7qByx6ew7A+HfnuQX3SjmNmZga4+DPLm0senMO6DRVcfcpgmjTx7l4zM6sfXPyZ5cFTb33Mg28u5kdHDGDALu3SjmNmZvZ/XPyZ1bJPN5Rz4f2zGLjrTpz99d3TjmNmZvYFLv7MatmvH3ubj1Z/xlWnDKFFM3/EzMysfvE3k1ktKl5Qxl0vv8+4g/tyQO+OaccxMzP7Ehd/ZrVkQ3kFE+4roXuH1vx81J5pxzEzM6tWwZzk2Szfrn/mXUqXfsptZx5I25b+aJmZWf3kkT+zWvDOx2u4/tlSThrancP33CXtOGZmZlvk4s9sB1VUBr+4dyY7tWzGRccNSjuOmZnZVrn4M9tBd720gBkfrGTS8fvQeaeWaccxMzPbKhd/Zjvgw5Xr+fXjc/n6wK6cOLR72nHMzMy2ycWf2XaKCC6YUgLAFSfvi+RLuJmZWf3n4s9sO019czHPzl3Gz47ak54d26Qdx8zMrEZc/Jlth7K1G7nkwTkM7bUz4w7pm3YcMzOzGnPxZ7YdLn9oDqvXb+LqU4bQtIl395qZWcPh4s8sR8+9s4z73viQfz9sd/bcrV3acczMzHLi4s8sB2s3lHP+fSXs3rUt5x4xIO04ZmZmOfM1qMxy8Nsn3uHDleu59+yDadmsadpxzMzMcuaRP7MaemPhCm7713xOH9GHor6d0o5jZma2XVIr/iR9U9JsSZWSijZbNlFSqaS5kkZltQ+TVJIsu07JidUktZR0T9L+iqS+WX3GSZqX3MbV2QZao7KxvJKJ95Wwa7tW/GL0nmnHMTMz225pjvzNAsYAz2c3ShoEjAX2AUYD10uq2r92AzAe2CO5jU7azwJWRMQA4Frg6uS5OgGTgIOA4cAkSR3zuE3WSN343Lu8/dEaLjtpX9q1ap52HDMzs+2WWvEXEW9FxNxqFp0I3B0RGyJiPlAKDJfUDWgfES9FRAB3Aidl9bkjuX8vcGQyKjgKmBYRZRGxApjG5wWjWY2ULv2UPzxdyrFDuvGNQbumHcfMzGyH1Mdj/noAH2Q9XpS09Ujub97+hT4RUQ6sAjpv5bnMaqSyMph430xat2jKxcfvk3YcMzOzHZbX2b6SngR2q2bRBRHxwJa6VdMWW2nf3j5ffFFpPJldyvTu3XsL0azQ/O3Vhby2YAW/OXUIXdu1TDuOmZnZDstr8RcRI7ej2yKgV9bjnsDipL1nNe3ZfRZJagZ0AMqS9sM26/PsFrLeBNwEUFRUVG2BaIVlyar1XPXo23xlQGdOHdZz2x3MzMwagPq423cqMDaZwduPzMSOVyNiCbBG0ojkeL4zgAey+lTN5D0VeDo5LvBx4ChJHZOJHkclbWZbFRFcdP8syisrufLkISQTy83MzBq81E7yLOlk4A9AV+BhSTMiYlREzJb0D2AOUA6cGxEVSbdzgNuB1sCjyQ3gFuAuSaVkRvzGAkREmaTLgNeS9S6NiLL8b501dI+UfMSTby3lgmP2pnfnNmnHMTMzqzXKDJBZtqKioiguLk47hqVk5bqNjPzv5+jWoTVT/v0QmjWtjwPkZmZmGZKmR0TRttfM8OXdzDZzxcNvsWLdJu74wXAXfmZm1uj4m80sy4vzlvPP6YsYf2h/9uneIe04ZmZmtc7Fn1li/cYKzp9SQr8ubfnPI/dIO46ZmVleeLevWeJ3T77DwrJ13D1+BK2aN912BzMzswbII39mQMmiVfzlhfc4bXgvRvTvnHYcMzOzvHHxZwVvU0Ul502eSZedWjLh6L3TjmNmZpZX3u1rBe/mF+YzZ8lq/vy9YXRo3TztOGZmZnnlkT8raPOXr+V3T77D6H12Y/S+1V2G2szMrHFx8WcFKyKYeN9MWjRrwiUn7pN2HDMzszrh4s8K1j2vfcDL75Vx/jF7s2v7VmnHMTMzqxMu/qwgLV39GVc88hYj+ndi7IG90o5jZmZWZ1z8WUGaNHU2G8oruXLMECSlHcfMzKzOuPizgvPYrI94dNZH/GTkHvTr0jbtOGZmZnXKxZ8VlFXrN/HLB2YxqFt7/t/X+qcdx8zMrM75PH9WUK569G2Wf7qBW8YdSPOm/tvHzMwKj7/9rGC8/N4n/P3Vhfzb1/ozuGeHtOOYmZmlwsWfFYTPNlUw8b4Sendqw09HDkw7jpmZWWq829cKwnVPzWP+8rX8z1kH0bpF07TjmJmZpcYjf9bozVm8mhuff49Th/Xkq3t0STuOmZlZqlz8WaNWXlHJhPtm0rFNcy48du+045iZmaXOu32tUbv9XwuYuWgVf/zO/uzcpkXacczMzFLnkT9rtBZ+so5rnpjLyL134djB3dKOY2ZmVi+kVvxJ+o2ktyXNlDRF0s5ZyyZKKpU0V9KorPZhkkqSZdcpuS6XpJaS7knaX5HUN6vPOEnzktu4utxGS09EcP6UEpo1acJlJ+3rS7iZmZkl0hz5mwbsGxFDgHeAiQCSBgFjgX2A0cD1kqqmZ94AjAf2SG6jk/azgBURMQC4Frg6ea5OwCTgIGA4MElSx/xvmqVt8usf8mLpcs47ei+6dWiddhwzM7N6I7XiLyKeiIjy5OHLQM/k/onA3RGxISLmA6XAcEndgPYR8VJEBHAncFJWnzuS+/cCRyajgqOAaRFRFhEryBScVQWjNVLL1mzgsofmUNSnI98d3jvtOGZmZvVKfTnm7wfAo8n9HsAHWcsWJW09kvubt3+hT1JQrgI6b+W5vkTSeEnFkoqXLVu2Qxtj6brkwdms31jBVacMpkkT7+41MzPLltfiT9KTkmZVczsxa50LgHLgr1VN1TxVbKV9e/t8sTHipogoioiirl27bmmTrJ57cs7HPDRzCT86YgADdmmXdhwzM7N6J6+neomIkVtbnkzAOA44MtmVC5nRuV5Zq/UEFiftPatpz+6zSFIzoANQlrQftlmfZ7djU6wBWPPZJi56YBZ77tqOs7++e9pxzMzM6qUaj/xJGijpKUmzksdDJF24vS8saTRwHnBCRKzLWjQVGJvM4O1HZmLHqxGxBFgjaURyPN8ZwANZfapm8p4KPJ0Uk48DR0nqmEz0OCpps0boN4/P5aPVn3HVKYNp0ay+HNFgZmZWv+TyDfkXMjNyNwFExEwys3K31x+BdsA0STMk/Tl53tnAP4A5wGPAuRFRkfQ5B7iZzCSQd/n8OMFbgM6SSoH/D5iQPFcZcBnwWnK7NGmzRqZ4QRl3vfw+3z+kL/v39oRuMzOzLdHne1u3saL0WkQcKOmNiNg/aZsREUPzGTANRUVFUVxcnHYMq6EN5RUce92LrN9YwRM/PZS2LX3hGjMzKxySpkdEUU3Xz+Vbcrmk3UkmTEg6FViSYz6zWvenZ96ldOmn3H7mgS78zMzMtiGXb8pzgZuAvSR9CMwHvpuXVGY1NPejNdzwbCkn79+Dw/bcJe04ZmZm9V6Nir/kChvnRMRISW2BJhGxJr/RzLauojI4b/JM2rVqzkXHDUo7jpmZWYNQo+IvIiokDUvur81vJLOaufOlBcz4YCW/+/ZQOrVtkXYcMzOzBiGX3b5vSJoK/BP4vwIwIu6r9VRm27BoxTp+8/hcDtuzKycO7Z52HDMzswYjl+KvE/AJcERWWwAu/qxORQQX3j8LgMtP2pfMaR/NzMysJmpc/EXEmfkMYlZTU99czLNzlzHp+EH07Ngm7ThmZmYNSi5X+OgpaYqkpZI+ljRZUs9t9zSrPWVrN3LJg3MY2mtnzji4b9pxzMzMGpxcrvBxG5nLqHUHegAPJm1mdeayh+aw5rNN/PrUITRt4t29ZmZmucql+OsaEbdFRHlyux3omqdcZl/y7NylTHnjQ845bAADd22XdhwzM7MGKZfib7mk70lqmty+R2YCiFnerd1QzgVTZrF717ace/juaccxMzNrsHIp/n4AfAv4iMxl3U5N2szy7pon5vLhyvVcfcoQWjZrmnYcMzOzBiuX2b4LgRPymMWsWm8sXMHt/1rA6SP6UNS3U9pxzMzMGrRcZvveIWnnrMcdJd2al1RmiY3llUyYXMJu7Vvxi9F7ph3HzMyswctlt++QiFhZ9SAiVgD713oisyw3Pvcucz9ew+Un7Uu7Vs3TjmNmZtbg5VL8NZHUseqBpE7kdoUQs5yULv2UPzxdynFDunHk3rumHcfMzKxRyKV4+y3wL0n3Jo+/CVxR+5HMoLIymHjfTFq3aMqk4/dJO46ZmVmjkcuEjzslFZO5tq+AMRExJ2/JrKD99dWFvLZgBdd8cz+6tmuZdhwzM7NGo8bFn6TdgXcjYo6kw4CRkhZnHwdoVhuWrFrP1Y++zVcHdOGUA3qkHcfMzKxRyeWYv8lAhaQBwM1AP+BveUllBSsiuOj+WZRXVvKrkwcj+RJuZmZmtSmX4q8yIsqBMcDvI+KnQLf8xLJC9XDJEp58ayn/9Y096d25TdpxzMzMGp1cir9Nkk4DzgAeStq2+9wbki6TNFPSDElPSOqetWyipFJJcyWNymofJqkkWXadkmEhSS0l3ZO0vyKpb1afcZLmJbdx25vX8m/luo1cPHU2Q3p24Myv9E07jpmZWaOUS/F3JnAwcEVEzJfUD/ifHXjt30TEkIgYSqaY/CWApEHAWGAfYDRwvaSq63ndAIwH9khuo5P2s4AVETEAuBa4OnmuTsAk4CBgODAp+3Q1Vr9c8fBbrFi3iavGDKFZ01x+NM3MzKymavwNGxFzIuLHEfH35PH8iLiqarmkybm8cESsznrYFojk/onA3RGxISLmA6XAcEndgPYR8VJEBHAncFJWnzuS+/cCRyajgqOAaRFRlpyUehqfF4xWj7w4bzn/nL6IHx7an0Hd26cdx8zMrNGqzZM098+1g6QryOxGXgUcnjT3AF7OWm1R0rYpub95e1WfDwAiolzSKqBzdns1fTbPMp7MqCK9e/fOdVNsB6zfWMH5U0ro16UtPz5yj7TjmJmZNWq1uW8tNm+Q9KSkWdXcTgSIiAsiohfwV+BHVd228Nxbat/ePl9sjLgpIooioqhr167VrWJ5cu2T77CwbB1XjhlMq+ZNt93BzMzMtlteL88WESNruOrfgIfJHJ+3COiVtawnsDhp71lNO1l9FklqBnQAypL2wzbr82wu22D5VbJoFTe/8B6nDe/NiP6d045jZmbW6NXmyF9OJ2STlL1/7wTg7eT+VGBsMoO3H5mJHa9GxBJgjaQRyfF8ZwAPZPWpmsl7KvB0clzg48BRkjomEz2OStqsHthUUcl5k2fSZaeWTDh6r7TjmJmZFYTaHPk7L8f1r5K0J1AJvA+cDRARsyX9A5gDlAPnRkRF0ucc4HagNfBocgO4BbhLUimZEb+xyXOVSboMeC1Z79KIKNuObbM8+MsL7zFnyWr+/L1hdGi93WcNMjMzsxwoM0C2lRWkEqo/Tk5ARMSQfARLU1FRURQXF6cdo1Gbv3wto373PEfutQs3fG9Y2nHMzMwaLEnTI6KopuvXZOTvuB3IY/YllZXBhMkzadmsCZecsE/acczMzArKNou/iHi/LoJY4fhH8Qe8Mr+Mq8YMZpf2rdKOY2ZmVlBqPOEjmWjxmqRPJW2UVCFp9bZ7mn3u49WfccUjbzGifye+fWCvbXcwMzOzWpXLbN8/AqcB88hMuPg34A/5CGWN16QHZrOxvJIrxwwhuTSzmZmZ1aGcTvUSEaVA04ioiIjb+PyqHGbb9NisJTw2+yN+MnIg/bq0TTuOmZlZQcrlVC/rJLUAZkj6NbCEzDV5zbZp1fpN/PKB2Qzq1p5/+1q/tOOYmZkVrFxG/k5P1v8RsJbMFTVOyUcoa3yuevRtln+6gatPGULzprV5bnEzMzPLRS4jfwcAj0TEauCSPOWxRujl9z7h768uZPyh/Rncs0PacczMzApaLkMwJwDvSLpL0rHJNXTNtuqzTRVMvK+E3p3a8NORA9OOY2ZmVvBqXPxFxJnAAOCfwHeAdyXdnK9g1jhc99Q85i9fy5VjBtO6RdO045iZmRW8nEbvImKTpEfJXO6tNXAimVO+mH3JnMWrufH59/jmsJ58ZUCXtOOYmZkZuZ3kebSk24FS4FTgZqBbnnJZA1deUcl5k2fSsU0LLjh277TjmJmZWSKXkb/vA3cDP4yIDfmJY43Fbf+7gJIPV/Gn7xzAzm1apB3HzMzMEjUu/iJi7NaWS3opIg7e8UjW0C38ZB2/nTaXkXvvyjGDd0s7jpmZmWWpzROutarF57IGKiI4f0oJzZo04bKT9vEl3MzMzOqZ2iz+ohafyxqoe6cv4sXS5Zx39F5069A67ThmZma2GV9qwWrNsjUbuPzhtziwb0e+O7x32nHMzMysGrVZ/Hn/XoG75MHZrN9YwZVjhtCkiX8czMzM6qNcTvXSVlKT5P5ASSdIap61yum1ns4ajCfnfMxDM5fwH0cMYMAuO6Udx8zMzLYgl5G/54FWknoATwFnArdXLYyIWbUbzRqKNZ9t4qIHZrHnru344dd3TzuOmZmZbUUuxZ8iYh0wBvhDRJwMDMpPLGtIfv3YXD5a/RlXnzqEFs18GKmZmVl9llPxJ+lg4LvAw0lbTpeHs8aneEEZd738Pmce0o+hvXZOO46ZmZltQy7F30+AicCUiJgtqT/wzI4GkPQzSSGpS1bbREmlkuZKGpXVPkxSSbLsOiUnkZPUUtI9Sfsrkvpm9RknaV5yG7ejee1zG8orOG/yTHrs3Jr/Ompg2nHMzMysBnK5wsdzwHMAycSP5RHx4x15cUm9gG8AC7PaBgFjgX2A7sCTkgZGRAVwAzAeeBl4BBgNPAqcBayIiAGSxgJXA9+W1AmYBBSROQ/hdElTI2LFjuS2jD89Xcq7y9Zyxw+G07alB4HNzMwaglxm+/5NUntJbYE5wFxJP9/B178W+AVfPEH0icDdEbEhIuYDpcBwSd2A9hHxUkQEcCdwUlafO5L79wJHJqOCo4BpEVGWFHzTyBSMtoPe/mg11z/7LmP278HXB3ZNO46ZmZnVUC67fQdFxGoyBdcjQG924PQukk4APoyINzdb1AP4IOvxoqStR3J/8/Yv9ImIcmAV0Hkrz1VdnvGSiiUVL1u2bLu2qVBUVAYTJpfQvnVzLjzOc37MzMwaklz21TVPzut3EvDHiNgkaauXdJP0JLBbNYsuAM4HjqquWzVtsZX27e3zxcaIm4CbAIqKinypuq2486UFzPhgJb8fO5RObVukHcfMzMxykEvxdyOwAHgTeF5SH2D11jpExMjq2iUNBvoBbyZzNnoCr0saTmZ0rlfW6j2BxUl7z2rayeqzSFIzoANQlrQftlmfZ7e6lbZVi1as4zePz+WwPbtywn7d045jZmZmOarxbt+IuC4iekTEMZHxPnD49rxoRJRExC4R0Tci+pIp0g6IiI+AqcDYZAZvP2AP4NWIWAKskTQiOZ7vDOCB5CmnAlUzeU8Fnk6OC3wcOEpSR0kdyYw0Pr49mQ0iggumZM7lfflJ+5IU7mZmZtaA1HjkT1IHMjNnD02angMuJXN8Xa1JTiPzDzKTSsqBc5OZvgDnkLmqSGsys3wfTdpvAe6SVEpmxG9s8lxlki4DXkvWuzQiymozbyF5YMZinntnGRcfP4ieHdukHcfMzMy2gzIDZDVYUZoMzOLzWbWnA/tFxJg8ZUtNUVFRFBcXpx2jXvnk0w2M/O/n6NulLfeefQhNm3jUz8zMrD6QND0iimq6fi7H/O0eEadkPb5E0owc+lsDdvnDb/HphnKuPmWICz8zM7MGLJdTvayX9NWqB5K+Aqyv/UhW3zw7dylT3viQcw4bwMBd26Udx8zMzHZALiN/ZwN3Jsf+Aazg80kW1kit3VDOBVNmMWCXnTj38N3TjmNmZmY7qEbFn6SmwPciYj9J7QGSEz5bI3fNE3NZvGo99559MC2bNU07jpmZme2gGhV/EVEhaVhy30VfgXhj4Qpu/9cCTh/Rh2F9OqUdx8zMzGpBLrt935A0FfgnsLaqMSLuq/VUlrqN5ZVMmFzCbu1b8fNRe6Ydx8zMzGpJLsVfJ+AT4IistgBc/DVCf37uXeZ+vIZbxhXRrlXztOOYmZlZLcml+GsC/GdErARIrpjx23yEsnSVLl3DH58u5fj9unPk3rumHcfMzMxqUS6nehlSVfgBRMQKYP9aT2SpqqwMJkwuoU3Lpkw6flDacczMzKyW5VL8NUlG+wCQ1IncRg6tAfjrK+9T/P4KLjx2EF12apl2HDMzM6tluRRvvwX+JeleMsf6fQu4Ii+pLBWLV67n6sfm8rU9unDKAT3SjmNmZmZ5UOPiLyLulFRMZsKHgDERMSdvyaxORQQX3T+LisrgVycPRvIl3MzMzBqjnHbbJsWeC75G6OGSJTz19lIuPHZvenVqk3YcMzMzy5NcjvmzRmrluo1cPHU2Q3p24PuH9E07jpmZmeWRJ2wYlz/8FivXbeLOHxxEs6b+e8DMzKwx8zd9gXtx3nLunb6IH369P4O6t087jpmZmeWZi78Ctn5jBROnzKR/l7b8xxF7pB3HzMzM6oB3+xawa598hw/K1nPP+BG0at407ThmZmZWBzzyV6BmLlrJzS+8x3cO6s1B/TunHcfMzMzqiIu/ArSpopLzJpfQZaeWTDh6r7TjmJmZWR3ybt8C9JcX3uOtJau58fRhtG/VPO04ZmZmVodSG/mTdLGkDyXNSG7HZC2bKKlU0lxJo7Lah0kqSZZdp+QyFJJaSronaX9FUt+sPuMkzUtu4+p0I+uh+cvX8rsn53H0vrsxap/d0o5jZmZmdSzt3b7XRsTQ5PYIgKRBwFhgH2A0cL2kqtkINwDjgT2S2+ik/SxgRUQMAK4Frk6eqxMwCTgIGA5MktSxTrasHqqsDCZMnkmrZk245IR90o5jZmZmKUi7+KvOicDdEbEhIuYDpcBwSd2A9hHxUkQEcCdwUlafO5L79wJHJqOCo4BpEVEWESuAaXxeMBace4o/4JX5ZVxw7N7s0r5V2nHMzMwsBWkXfz+SNFPSrVkjcj2AD7LWWZS09Ujub97+hT4RUQ6sAjpv5bm+RNJ4ScWSipctW7ZjW1UPfbz6M371yFsc3L8z3yrqlXYcMzMzS0leiz9JT0qaVc3tRDK7cHcHhgJLgN9WdavmqWIr7dvb54uNETdFRFFEFHXt2nXLG9VATXpgNhvLK/nVmMEkh0qamZlZAcrrbN+IGFmT9ST9BXgoebgIyB6a6gksTtp7VtOe3WeRpGZAB6AsaT9ssz7P5rINjcFjs5bw2OyPOG/0XvTr0jbtOGZmZpaiNGf7dst6eDIwK7k/FRibzODtR2Zix6sRsQRYI2lEcjzfGcADWX2qZvKeCjydHBf4OHCUpI7JbuWjkraCsWr9Ji56YDb7dG/P//tav7TjmJmZWcrSPM/fryUNJbMbdgHwQ4CImC3pH8AcoBw4NyIqkj7nALcDrYFHkxvALcBdkkrJjPiNTZ6rTNJlwGvJepdGRFl+N6t+uerRtyhbu5Hbvn8gzZqmfYinmZmZpU2ZATLLVlRUFMXFxWnH2GEvvfsJp/3lZX54aH8mHrN32nHMzMwsDyRNj4iimq7voaBG6rNNFUy8byZ9OrfhJyMHph3HzMzM6glf3q2R+v1T81jwyTr+9m8H0bpF0213MDMzs4Lgkb9GaPbiVdz0/Ht8q6gnhwzoknYcMzMzq0dc/DUy5RWVTJhcQsc2LTjfx/mZmZnZZrzbt5G57X8XUPLhKv70nQPYuU2LtOOYmZlZPeORv0bk/U/W8ttpc/nGoF05ZvBuaccxMzOzesjFXyMREZw/pYTmTZpw2Yn7+hJuZmZmVi0Xf43EvdMX8b+ln3De0XuxW4dWaccxMzOzesrFXyOwbM0GLn/4LYb37cR3hvdOO46ZmZnVYy7+GoGLH5zN+o0VXHnKYJo08e5eMzMz2zIXfw3ctDkf8/DMJfz4yAHs3nWntOOYmZlZPefirwFb89kmLrp/Fnvt1o7xh+6edhwzMzNrAHyevwbs14/N5eM1n/Hn04fRopnreDMzM9s2VwwN1GsLyrjr5fc585B+DO21c9pxzMzMrIFw8dcAfbapggmTZ9KzY2t+Nmpg2nHMzMysAfFu3wbo+mdKeXfZWu74wXDatPBbaGZmZjXnkb8G5u2PVnP9s+8yZv8efH1g17TjmJmZWQPj4q8BqagMJkwuoX3r5lx43KC045iZmVkD5OKvAbnjXwuY8cFKJh0/iE5tW6Qdx8zMzBogF38NxAdl67jmibkcvmdXTtive9pxzMzMrIFy8dcARAQX3D8LgMtPHozkS7iZmZnZ9km1+JP0H5LmSpot6ddZ7RMllSbLRmW1D5NUkiy7TkkVJKmlpHuS9lck9c3qM07SvOQ2rk43sJY8MGMxz7+zjF+M2pMeO7dOO46ZmZk1YKmdJ0TS4cCJwJCI2CBpl6R9EDAW2AfoDjwpaWBEVAA3AOOBl4FHgNHAo8BZwIqIGCBpLHA18G1JnYBJQBEQwHRJUyNiRV1u64745NMNXPLgbA7ovTOnH9w37ThmZmbWwKU58ncOcFVEbACIiKVJ+4nA3RGxISLmA6XAcEndgPYR8VJEBHAncFJWnzuS+/cCRyajgqOAaRFRlhR808gUjA3GZQ/N4dMN5Vx1yhCaNvHuXjMzM9sxaRZ/A4GvJbtpn5N0YNLeA/gga71FSVuP5P7m7V/oExHlwCqg81ae60skjZdULKl42bJlO7RhteWZuUu5f8Zi/v2wAQzctV3acczMzKwRyOtuX0lPArtVs+iC5LU7AiOAA4F/SOoPVDe8FVtpZzv7fLEx4ibgJoCioqJq16lLazeUc+GUWQzYZSf+/fDd045jZmZmjURei7+IGLmlZZLOAe5LduG+KqkS6EJmdK5X1qo9gcVJe89q2snqs0hSM6ADUJa0H7ZZn2e3f4vqzm8en8viVeu59+xDaNmsadpxzMzMrJFIc7fv/cARAJIGAi2A5cBUYGwyg7cfsAfwakQsAdZIGpEcz3cG8EDyXFOBqpm8pwJPJ0Xl48BRkjpK6ggclbTVa68vXMEdLy3gjBF9GNanY9pxzMzMrBFJbbYvcCtwq6RZwEZgXFKwzZb0D2AOUA6cm8z0hcwkkduB1mRm+T6atN8C3CWplMyI31iAiCiTdBnwWrLepRFRlvct2wEbyyuZMHkmu7Vvxc9H75V2HDMzM2tklKm3LFtRUVEUFxen8trXPTWP/572Drd+v4gj9to1lQxmZmbWcEiaHhFFNV3fV/ioR0qXruGPT5dywn7dXfiZmZlZXrj4qycqK4PzJpfQpmVTfnn8oLTjmJmZWSPl4q+e+Osr7zP9/RVcdOwguuzUMu04ZmZm1ki5+KsHFq9cz9WPzeVre3RhzAHVnoPazMzMrFa4+EtZRHDR/bOoqAx+dfJgMmexMTMzM8sPF38pe2jmEp56eyn/ddRAenVqk3YcMzMza+Rc/KVoxdqNXDx1Nvv17MCZX+mXdhwzMzMrAGme5LngXfHIW6xav4m7zjqIpk28u9fMzMzyzyN/KXlh3jLunb6IH369P4O6t087jpmZmRUIF38pWLexnPOnlNC/S1v+44g90o5jZmZmBcS7fVOwYVMlQ3rszBkH96FV86ZpxzEzM7MC4uIvBR3btuBP3z0g7RhmZmZWgLzb18zMzKyAuPgzMzMzKyAu/szMzMwKiIs/MzMzswLi4s/MzMysgLj4MzMzMysgLv7MzMzMCoiLPzMzM7MCoohIO0O9I2kZ8H4dvFQXYHkdvI7VP37vC5Pf98Ll975w1cV73yciutZ0ZRd/KZJUHBFFaeewuuf3vjD5fS9cfu8LV318773b18zMzKyAuPgzMzMzKyAu/tJ1U9oBLDV+7wuT3/fC5fe+cNW7997H/JmZmZkVEI/8mZmZmRUQF39mZmZmBcTFXx5ICkl3ZT1uJmmZpIeSx9+X9Mdq+i2QVCJppqTnJPWpy9xW+yRVSJohaZakByXtnLT3lbQ+WVZ1a5Fy3IIj6eTk87rXVtZ5VlJRcv+Rqvcwx9c5TNIh29FvgaQuW2iv9ndF1s9c1a1vrq9r2y/r//9NSa9Xve+bfebnSLpTUvO08xaiRvC5n5H8e2LWsmq/a7bExV9+rAX2ldQ6efwN4MMa9j08IoYAzwIX5iGb1a31ETE0IvYFyoBzs5a9myyrum1MKWMhOw14ERhbk5Uj4piIWLkdr3MYkPOXwDZs6XfF+s1+rhbU8uva1lX9/+8HTASuzFr2bkQMBQYDPYFvpZDPGv7nfihwKnBdVvvWvmu+xMVf/jwKHJvcPw34e479XwJ61GoiS5vf03pE0k7AV4CzyPoSkNRa0t3JqNo9QOusZQskdUlGcWZltf9M0sXJ/R8nIzszk+fpC5wN/DT5y/xrkrpKmizpteT2laRvZ0lPSHpD0o2AarAp/rmqv9oDKzZvjIgK4FX8vtW5RvS5r/ZnK7HN3wnNavACtn3uBn6pzK7eIcCtwNdy6D8auD8PuSwFkpoCRwK3ZDXvLmlGcv9/I2Krf6lZrTsJeCwi3pFUJumAiHgdOAdYFxFDJA0BXs/xeScA/SJig6SdI2KlpD8Dn0bENQCS/gZcGxEvSuoNPA7sDUwCXoyISyUdC4yvwett/ruiddbP1fyIODnH/LZjqv7/WwHdgCM2X0FSK+Ag4D/rNprR8D/3z0gS0J9qRo638F3zJS7+8iQiZiaV/2nAIzl0fUbSrsBSvNu3Maj6IugLTAemZS2r2gVk6TgN+F1y/+7k8evAoSS7U5LP8cwcn3cm8FdJ97PlP+BGAoMyv8MBaC+pXfLaY5LXfljSlv6yhy3/rljvn6tU/d//v6SDgTsl7Zssq/qDbw/g3ojI9WfLdlxD/9wfHhHLJe0OPCXp2Yj4lK1/13yJd/vm11TgGnLb5Xs40AeYDVyaj1BWp6q+CPoALdjGcRhWNyR1JjMic7OkBcDPgW/r89/K2zoBajlf/P3ZKuv+scCfgGHAdEnV/ZHdBDg467i8HhGxpoavXcW/K+q5iHgJ6AJ0TZqq/uAbAIyQdEJa2QpRI/ncZ1aOeBf4GBiUNOX0XePiL79uBS6NiJJcOkXEeuAnwBmSOuUjmNWtiFgF/Bj4mTzDrz44FbgzIvpERN+I6AXMB74KPA98FyAZsRlSTf+PgV2SY3VaAscl6zcBekXEM8AvgJ2BnYA1QLus/k8AP6p6IGlocjf7tY8GOm5tI/y7on5TZjZpU+CT7PaIWEJmN+HENHIVsEbxuU/W2wXoB7yf3V7T7xoXf3kUEYsi4vdbWPx9SYuybj0367uEzIihR4oaiYh4A3iTGs4ws7w6DZiyWdtk4DvADcBOyW6fX5A5MD9bRMQmMqNtrwAPAW8ny5oC/yOpBHiDzPE9K4EHgZOrDvwm88u5KDk4fA6ZA8MBLgEOlfQ6cBSwcFsb4t8V9U7r5H2eAdwDjEsmeGzufqBN8vNgdaMxfO6fSX62ngEmRMTHm69Qk+8aX97NzKwGkgOplwK7JV8CZtbINdbPvUf+zMxqZjZwc2P6AjCzbWqUn3uP/JmZmZkVEI/8mZmZmRUQF39mZmZmBcTFn5mZmVkBcfFnZlZDkkLSXVmPm0lallzGMZfnWSCpy46uY2a2PVz8mZnV3FpgX0lVF33/BvBhinnMzHLm4s/MLDePkrmUE2ROGvt/l2+U1EnS/clJXF9OLhBPckWAJyS9IelGQFl9vifp1eREsDcm5xUja3lbSQ9LelPSLEnfzv8mmllj5uLPzCw3dwNjJbUicwmoV7KWXQK8ERFDgPOBO5P2ScCLEbE/mWt+9waQtDfwbeAryXU5K0gu85RlNLA4IvaLiH2Bx/KyVWZWMKq78LCZmW1BRMyU1JfMqN8jmy3+KnBKst7TyYhfB+BQYEzS/rCkFcn6R5K5EPxrybXlW5O5mkC2EuAaSVcDD0XEC7W/VWZWSFz8mZnlbipwDXAY0DmrXdWsG5v9m03AHRExcUsvFBHvSBoGHANcKemJiLh0u1KbmeHdvmZm2+NW4NKIKNms/XmS3baSDgOWR8TqzdqPBjom6z8FnCppl2RZJ0l9sp9QUndgXUT8D5mC84B8bJCZFQ6P/JmZ5SgiFgG/r2bRxcBtkmYC64BxSfslwN8lvQ48ByxMnmeOpAuBJyQ1ATYB5wLvZz3nYOA3kiqT5efU/haZWSHxtX3NzMzMCoh3+5qZmZkVEBd/ZmZmZgXExZ+ZmZlZAXHxZ2ZmZlZAXPyZmZmZFRAXf2ZmZmYFxMWfmZmZWQH5/wGec9ri0sakSgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting the cross_val_scores outputs\n",
    "plt.figure(figsize = (10,4))\n",
    "plt.plot(df_scores[\"Model Type\"], df_scores[\"Cross-validation score\"])\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"cross_val_score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377f9d3c-2419-408c-945e-0a5789223903",
   "metadata": {},
   "source": [
    "All things considered, the Random Forest model with tuning hyperparameters has a considerably low MSE and a significant R-squared value which assist us to have more precise predictions based on the test dataset. Therefore, the Random Forest Regressor is the optimal model out of three."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "699b13db-9596-4280-b1fe-c3979ab8dad9",
   "metadata": {},
   "source": [
    "### Predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9040f78f-5cb0-4194-b463-39138b8db63e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 52)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Specify subset\n",
    "test_input = df_test.drop(['ID','name','description','neighborhood_overview','host_name','host_since','host_location','host_about','host_neighbourhood','neighbourhood','neighbourhood_cleansed','first_review','last_review','license'],axis=1)\n",
    "#Subset size\n",
    "test_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "21288e71-96e7-43e3-b849-9649d6535536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 49.81913358, 174.03116443, 179.30484841, ..., 245.28595734,\n",
       "       219.37817902, 280.38274183])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict the corresponding prices\n",
    "submission = tune_forest.predict(test_input)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e4314e28-11a7-4066-a999-41e93f4d5c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set new column for price in the test set\n",
    "df_test['price'] = submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "9a07fcc4-81f8-44f9-85f4-ab71721fb13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert 2 columns of ID and price to a submission file\n",
    "df_test[['ID','price']].to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
